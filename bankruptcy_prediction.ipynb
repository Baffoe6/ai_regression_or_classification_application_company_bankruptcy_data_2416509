{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Company Bankruptcy Prediction\n",
        "\n",
        "## Overview\n",
        "This notebook predicts company bankruptcy using financial indicators.\n",
        "\n",
        "### Problem Type: Classification\n",
        "- **Target Variable**: Bankrupt? (Y) - Binary classification (0: Not Bankrupt, 1: Bankrupt)\n",
        "- **Features**: 95 financial indicators (X1-X95)\n",
        "- **Models**:\n",
        "  1. Logistic Regression (with configurations)\n",
        "  2. Random Forest (with configurations)\n",
        "  3. Neural Network (with configurations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score, f1_score, precision_score, recall_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Documentation Reference\n",
        "\n",
        "The dataset includes 95 financial features (X1-X95) as documented in `CompanyBankruptcyData Documentation.txt`. Each feature represents various financial ratios and indicators that can help predict bankruptcy risk, such as:\n",
        "\n",
        "- Return on Assets (ROA) metrics\n",
        "- Operating margins and profit rates\n",
        "- Current ratios and quick ratios\n",
        "- Debt-to-equity ratios\n",
        "- Cash flow indicators\n",
        "- Growth rates (asset, equity, profit)\n",
        "- Turnover ratios\n",
        "- Financial leverage indicators\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('CompanyBankruptcyData.csv')\n",
        "\n",
        "# Display basic information\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {df.shape[1]}\")\n",
        "print(f\"Rows: {df.shape[0]}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values per column:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# Data info\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df.drop('Bankrupt?', axis=1)\n",
        "y = df['Bankrupt?']\n",
        "\n",
        "print(f\"Target distribution:\")\n",
        "print(y.value_counts())\n",
        "print(f\"\\nTarget distribution (%):\")\n",
        "print(y.value_counts(normalize=True) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize target distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "target_counts = y.value_counts()\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(['Not Bankrupt (0)', 'Bankrupt (1)'], target_counts.values, color=['green', 'red'], alpha=0.7)\n",
        "plt.title('Target Class Distribution (Count)', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Count')\n",
        "for i, v in enumerate(target_counts.values):\n",
        "    plt.text(i, v + 50, str(v), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(target_counts.values, labels=['Not Bankrupt', 'Bankrupt'], autopct='%1.2f%%', \n",
        "        colors=['green', 'red'], startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
        "plt.title('Target Class Distribution (%)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display feature information\n",
        "print(f\"Total features: {len(X.columns)}\")\n",
        "print(f\"\\nFirst 10 features:\")\n",
        "for i, col in enumerate(X.columns[:10], 1):\n",
        "    print(f\"{i}. {col}\")\n",
        "\n",
        "print(f\"\\nLast 10 features:\")\n",
        "for i, col in enumerate(X.columns[-10:], len(X.columns)-9):\n",
        "    print(f\"{i}. {col}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation Heatmap Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create correlation heatmap for top features\n",
        "correlation_matrix = df.corr()\n",
        "top_features = correlation_with_target.abs().sort_values(ascending=False).head(20).index\n",
        "\n",
        "plt.figure(figsize=(14, 12))\n",
        "correlation_subset = correlation_matrix.loc[['Bankrupt?'] + list(top_features), \n",
        "                                              ['Bankrupt?'] + list(top_features)]\n",
        "sns.heatmap(correlation_subset, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, fmt='.2f')\n",
        "plt.title('Correlation Heatmap: Bankruptcy Target vs Top 20 Features', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize distributions of top predictive features\n",
        "top_features_list = correlation_with_target.abs().sort_values(ascending=False).head(12).index\n",
        "\n",
        "fig, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(top_features_list):\n",
        "    data_bankrupt = df[df['Bankrupt?'] == 1][feature]\n",
        "    data_non_bankrupt = df[df['Bankrupt?'] == 0][feature]\n",
        "    \n",
        "    axes[i].hist(data_non_bankrupt, bins=30, alpha=0.6, label='Not Bankrupt', \n",
        "                color='green', edgecolor='black')\n",
        "    axes[i].hist(data_bankrupt, bins=30, alpha=0.6, label='Bankrupt', \n",
        "                color='red', edgecolor='black')\n",
        "    axes[i].set_title(f'{feature[:45]}...' if len(feature) > 45 else feature, \n",
        "                     fontsize=9, fontweight='bold')\n",
        "    axes[i].set_xlabel('Value')\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define evaluation function with confusion matrix\n",
        "def evaluate_model(y_true, y_pred, y_pred_proba, model_name):\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{model_name} - Evaluation Results\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
        "    \n",
        "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"ROC-AUC: {auc:.4f}\")\n",
        "    \n",
        "    print(f\"\\n{'-'*60}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(f\"{'-'*60}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"\\n{'-'*60}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(f\"{'-'*60}\")\n",
        "    print(cm)\n",
        "    \n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'ROC-AUC': auc,\n",
        "        'Confusion_Matrix': cm\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis with target\n",
        "correlation_with_target = df.corr()['Bankrupt?'].sort_values(ascending=False).drop('Bankrupt?')\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_correlations = pd.concat([correlation_with_target.head(10), correlation_with_target.tail(10)])\n",
        "plt.barh(range(len(top_correlations)), top_correlations.values, color='steelblue', alpha=0.7)\n",
        "plt.yticks(range(len(top_correlations)), top_correlations.index)\n",
        "plt.xlabel('Correlation with Bankrupt?', fontsize=12, fontweight='bold')\n",
        "plt.title('Top 20 Features Most Correlated with Bankruptcy', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"\\nTraining set class distribution:\")\n",
        "print(y_train.value_counts())\n",
        "print(f\"\\nTest set class distribution:\")\n",
        "print(y_test.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data scaled successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define evaluation function\n",
        "def evaluate_model(y_true, y_pred, y_pred_proba, model_name):\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{model_name} - Evaluation Results\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
        "    \n",
        "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"ROC-AUC: {auc:.4f}\")\n",
        "    \n",
        "    print(f\"\\n{'-'*60}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(f\"{'-'*60}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    \n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'ROC-AUC': auc\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Logistic Regression - Configuration 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression - Config 1: Default settings\n",
        "lr_model1 = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
        "lr_model1.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_lr1 = lr_model1.predict(X_test_scaled)\n",
        "y_pred_proba_lr1 = lr_model1.predict_proba(X_test_scaled)\n",
        "\n",
        "results_lr1 = evaluate_model(y_test, y_pred_lr1, y_pred_proba_lr1, \n",
        "                            \"Logistic Regression - Config 1 (Default)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Logistic Regression - Configuration 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression - Config 2: L2 regularization with C=0.1\n",
        "lr_model2 = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', C=0.1, penalty='l2')\n",
        "lr_model2.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_lr2 = lr_model2.predict(X_test_scaled)\n",
        "y_pred_proba_lr2 = lr_model2.predict_proba(X_test_scaled)\n",
        "\n",
        "results_lr2 = evaluate_model(y_test, y_pred_lr2, y_pred_proba_lr2, \n",
        "                            \"Logistic Regression - Config 2 (C=0.1, L2)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Logistic Regression - Configuration 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression - Config 3: L1 regularization with C=10\n",
        "lr_model3 = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', C=10, penalty='l1')\n",
        "lr_model3.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_lr3 = lr_model3.predict(X_test_scaled)\n",
        "y_pred_proba_lr3 = lr_model3.predict_proba(X_test_scaled)\n",
        "\n",
        "results_lr3 = evaluate_model(y_test, y_pred_lr3, y_pred_proba_lr3, \n",
        "                            \"Logistic Regression - Config 3 (C=10, L1)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Random Forest - Configuration 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest - Config 1: Default settings\n",
        "rf_model1 = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_model1.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf1 = rf_model1.predict(X_test)\n",
        "y_pred_proba_rf1 = rf_model1.predict_proba(X_test)\n",
        "\n",
        "results_rf1 = evaluate_model(y_test, y_pred_rf1, y_pred_proba_rf1, \n",
        "                            \"Random Forest - Config 1 (Default)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Random Forest - Configuration 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest - Config 2: Deeper trees with more estimators\n",
        "rf_model2 = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5, \n",
        "                                   random_state=42, n_jobs=-1)\n",
        "rf_model2.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf2 = rf_model2.predict(X_test)\n",
        "y_pred_proba_rf2 = rf_model2.predict_proba(X_test)\n",
        "\n",
        "results_rf2 = evaluate_model(y_test, y_pred_rf2, y_pred_proba_rf2, \n",
        "                            \"Random Forest - Config 2 (n_estimators=200, max_depth=20)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.6 Random Forest - Configuration 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest - Config 3: Shallow trees with class balancing\n",
        "rf_model3 = RandomForestClassifier(n_estimators=150, max_depth=10, min_samples_split=10,\n",
        "                                   class_weight='balanced', random_state=42, n_jobs=-1)\n",
        "rf_model3.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf3 = rf_model3.predict(X_test)\n",
        "y_pred_proba_rf3 = rf_model3.predict_proba(X_test)\n",
        "\n",
        "results_rf3 = evaluate_model(y_test, y_pred_rf3, y_pred_proba_rf3, \n",
        "                            \"Random Forest - Config 3 (Class Weight Balanced)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.7 Neural Network - Configuration 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import TensorFlow/Keras for Neural Network\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Neural Network - Config 1: Simple architecture\n",
        "def create_nn1(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train model\n",
        "nn_model1 = create_nn1(X_train_scaled.shape[1])\n",
        "nn_model1.summary()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train model\n",
        "history1 = nn_model1.fit(X_train_scaled, y_train, \n",
        "                         validation_split=0.2,\n",
        "                         epochs=100,\n",
        "                         batch_size=32,\n",
        "                         callbacks=[early_stopping],\n",
        "                         verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_proba_nn1 = nn_model1.predict(X_test_scaled)\n",
        "y_pred_nn1 = (y_pred_proba_nn1 > 0.5).astype(int).ravel()\n",
        "y_pred_proba_nn1_formatted = np.column_stack([1 - y_pred_proba_nn1.ravel(), y_pred_proba_nn1.ravel()])\n",
        "\n",
        "results_nn1 = evaluate_model(y_test, y_pred_nn1, y_pred_proba_nn1_formatted, \n",
        "                            \"Neural Network - Config 1 (64-32)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.8 Neural Network - Configuration 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Neural Network - Config 2: Deeper architecture with RMSprop\n",
        "def create_nn2(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train model\n",
        "nn_model2 = create_nn2(X_train_scaled.shape[1])\n",
        "nn_model2.summary()\n",
        "\n",
        "# Train model\n",
        "history2 = nn_model2.fit(X_train_scaled, y_train, \n",
        "                         validation_split=0.2,\n",
        "                         epochs=100,\n",
        "                         batch_size=16,\n",
        "                         callbacks=[early_stopping],\n",
        "                         verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_proba_nn2 = nn_model2.predict(X_test_scaled)\n",
        "y_pred_nn2 = (y_pred_proba_nn2 > 0.5).astype(int).ravel()\n",
        "y_pred_proba_nn2_formatted = np.column_stack([1 - y_pred_proba_nn2.ravel(), y_pred_proba_nn2.ravel()])\n",
        "\n",
        "results_nn2 = evaluate_model(y_test, y_pred_nn2, y_pred_proba_nn2_formatted, \n",
        "                            \"Neural Network - Config 2 (128-64-32)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.9 Neural Network - Configuration 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Neural Network - Config 3: Wide shallow network with SGD\n",
        "def create_nn3(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(256, activation='tanh', input_shape=(input_dim,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='tanh'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train model\n",
        "nn_model3 = create_nn3(X_train_scaled.shape[1])\n",
        "nn_model3.summary()\n",
        "\n",
        "# Train model\n",
        "history3 = nn_model3.fit(X_train_scaled, y_train, \n",
        "                         validation_split=0.2,\n",
        "                         epochs=100,\n",
        "                         batch_size=64,\n",
        "                         callbacks=[early_stopping],\n",
        "                         verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_proba_nn3 = nn_model3.predict(X_test_scaled)\n",
        "y_pred_nn3 = (y_pred_proba_nn3 > 0.5).astype(int).ravel()\n",
        "y_pred_proba_nn3_formatted = np.column_stack([1 - y_pred_proba_nn3.ravel(), y_pred_proba_nn3.ravel()])\n",
        "\n",
        "results_nn3 = evaluate_model(y_test, y_pred_nn3, y_pred_proba_nn3_formatted, \n",
        "                            \"Neural Network - Config 3 (256-128, SGD)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Comparison and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all results\n",
        "all_results = [results_lr1, results_lr2, results_lr3, \n",
        "               results_rf1, results_rf2, results_rf3,\n",
        "               results_nn1, results_nn2, results_nn3]\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df.sort_values('ROC-AUC', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL MODEL COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization of Training and Validation Loss Curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history for all neural network models\n",
        "fig, axes = plt.subplots(3, 2, figsize=(16, 14))\n",
        "\n",
        "# Plot history1 (NN Config 1)\n",
        "axes[0, 0].plot(history1.history['loss'], label='Training Loss', linewidth=2)\n",
        "axes[0, 0].plot(history1.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[0, 0].set_title('NN Config 1 (64-32): Loss Curves', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].plot(history1.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "axes[0, 1].plot(history1.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "axes[0, 1].set_title('NN Config 1 (64-32): Accuracy Curves', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Accuracy')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot history2 (NN Config 2)\n",
        "axes[1, 0].plot(history2.history['loss'], label='Training Loss', linewidth=2, color='orange')\n",
        "axes[1, 0].plot(history2.history['val_loss'], label='Validation Loss', linewidth=2, color='red')\n",
        "axes[1, 0].set_title('NN Config 2 (128-64-32): Loss Curves', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Loss')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].plot(history2.history['accuracy'], label='Training Accuracy', linewidth=2, color='orange')\n",
        "axes[1, 1].plot(history2.history['val_accuracy'], label='Validation Accuracy', linewidth=2, color='red')\n",
        "axes[1, 1].set_title('NN Config 2 (128-64-32): Accuracy Curves', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Accuracy')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot history3 (NN Config 3)\n",
        "axes[2, 0].plot(history3.history['loss'], label='Training Loss', linewidth=2, color='green')\n",
        "axes[2, 0].plot(history3.history['val_loss'], label='Validation Loss', linewidth=2, color='darkgreen')\n",
        "axes[2, 0].set_title('NN Config 3 (256-128): Loss Curves', fontsize=12, fontweight='bold')\n",
        "axes[2, 0].set_xlabel('Epoch')\n",
        "axes[2, 0].set_ylabel('Loss')\n",
        "axes[2, 0].legend()\n",
        "axes[2, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2, 1].plot(history3.history['accuracy'], label='Training Accuracy', linewidth=2, color='green')\n",
        "axes[2, 1].plot(history3.history['val_accuracy'], label='Validation Accuracy', linewidth=2, color='darkgreen')\n",
        "axes[2, 1].set_title('NN Config 3 (256-128): Accuracy Curves', fontsize=12, fontweight='bold')\n",
        "axes[2, 1].set_xlabel('Epoch')\n",
        "axes[2, 1].set_ylabel('Accuracy')\n",
        "axes[2, 1].legend()\n",
        "axes[2, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrices for All Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize confusion matrices for all models\n",
        "fig, axes = plt.subplots(3, 3, figsize=(18, 16))\n",
        "\n",
        "models_confusion = [\n",
        "    (y_pred_lr1, \"Logistic Regression Config 1\", 0, 0),\n",
        "    (y_pred_lr2, \"Logistic Regression Config 2\", 0, 1),\n",
        "    (y_pred_lr3, \"Logistic Regression Config 3\", 0, 2),\n",
        "    (y_pred_rf1, \"Random Forest Config 1\", 1, 0),\n",
        "    (y_pred_rf2, \"Random Forest Config 2\", 1, 1),\n",
        "    (y_pred_rf3, \"Random Forest Config 3\", 1, 2),\n",
        "    (y_pred_nn1, \"Neural Network Config 1\", 2, 0),\n",
        "    (y_pred_nn2, \"Neural Network Config 2\", 2, 1),\n",
        "    (y_pred_nn3, \"Neural Network Config 3\", 2, 2)\n",
        "]\n",
        "\n",
        "for y_pred, name, row, col in models_confusion:\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[row, col],\n",
        "                cbar_kws={\"shrink\": 0.8}, square=True, linewidths=2)\n",
        "    axes[row, col].set_title(name, fontsize=10, fontweight='bold')\n",
        "    axes[row, col].set_xlabel('Predicted')\n",
        "    axes[row, col].set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Validation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform cross-validation on best models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CROSS-VALIDATION RESULTS (5-Fold)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Cross-validation for best logistic regression\n",
        "cv_lr = cross_val_score(lr_model1, X_train_scaled, y_train, cv=5, \n",
        "                        scoring='roc_auc', n_jobs=-1)\n",
        "print(f\"\\nLogistic Regression Config 1:\")\n",
        "print(f\"  Mean AUC: {cv_lr.mean():.4f} (±{cv_lr.std():.4f})\")\n",
        "\n",
        "# Cross-validation for best random forest\n",
        "cv_rf = cross_val_score(rf_model2, X_train, y_train, cv=5, \n",
        "                        scoring='roc_auc', n_jobs=-1)\n",
        "print(f\"\\nRandom Forest Config 2:\")\n",
        "print(f\"  Mean AUC: {cv_rf.mean():.4f} (±{cv_rf.std():.4f})\")\n",
        "\n",
        "# Cross-validation accuracy\n",
        "cv_acc_lr = cross_val_score(lr_model1, X_train_scaled, y_train, cv=5, \n",
        "                            scoring='accuracy', n_jobs=-1)\n",
        "cv_acc_rf = cross_val_score(rf_model2, X_train, y_train, cv=5, \n",
        "                            scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "print(f\"\\nAccuracy Scores:\")\n",
        "print(f\"  Logistic Regression: {cv_acc_lr.mean():.4f} (±{cv_acc_lr.std():.4f})\")\n",
        "print(f\"  Random Forest: {cv_acc_rf.mean():.4f} (±{cv_acc_rf.std():.4f})\")\n",
        "\n",
        "# Visualize cross-validation results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# AUC comparison\n",
        "axes[0].boxplot([cv_lr, cv_rf], labels=['Logistic Regression', 'Random Forest'])\n",
        "axes[0].set_title('Cross-Validation AUC Score Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('AUC Score')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy comparison\n",
        "axes[1].boxplot([cv_acc_lr, cv_acc_rf], labels=['Logistic Regression', 'Random Forest'])\n",
        "axes[1].set_title('Cross-Validation Accuracy Score Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Accuracy Score')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Justification and Theoretical Background\n",
        "\n",
        "### 1. Logistic Regression\n",
        "**Theoretical Justification:**\n",
        "- Logistic Regression is appropriate for binary classification problems\n",
        "- Uses the sigmoid function to model the probability of bankruptcy\n",
        "- **Regularization:** \n",
        "  - L1 (Lasso): Promotes feature selection by driving coefficients to zero\n",
        "  - L2 (Ridge): Prevents overfitting by penalizing large coefficients\n",
        "- **C Parameter:** Controls regularization strength (lower C = stronger regularization)\n",
        "- Reference: Hastie et al. (2009) - Elements of Statistical Learning\n",
        "\n",
        "**Configuration Choices:**\n",
        "- Config 1: Default (balanced regularization)\n",
        "- Config 2: C=0.1 with L2 (stronger regularization for overfitting prevention)\n",
        "- Config 3: C=10 with L1 (feature selection for interpretability)\n",
        "\n",
        "### 2. Random Forest\n",
        "**Theoretical Justification:**\n",
        "- Ensemble method combining multiple decision trees via bagging\n",
        "- Reduces overfitting through averaging multiple trees\n",
        "- Handles non-linear relationships and feature interactions\n",
        "- **Hyperparameter Impact:**\n",
        "  - `n_estimators`: More trees reduce variance (200 provides good bias-variance tradeoff)\n",
        "  - `max_depth`: Controls overfitting (deeper trees capture more patterns, depth=20 balances complexity)\n",
        "  - `min_samples_split`: Prevents overfitting (higher values = simpler trees)\n",
        "  - `class_weight='balanced'`: Addresses imbalanced classes by adjusting tree splitting\n",
        "- Reference: Breiman (2001) - Random Forests\n",
        "\n",
        "**Configuration Choices:**\n",
        "- Config 1: Default (quick baseline)\n",
        "- Config 2: Deeper trees (max_depth=20) with more estimators (200) for better performance\n",
        "- Config 3: Balanced class weights to handle minority class (bankrupt companies)\n",
        "\n",
        "### 3. Neural Network\n",
        "**Theoretical Justification:**\n",
        "- Deep learning captures complex non-linear patterns in financial data\n",
        "- **Architecture Choices:**\n",
        "  - ReLU activation: Non-saturating, prevents vanishing gradients (Glorot et al., 2011)\n",
        "  - Dropout: Regularization technique to prevent co-adaptation (Srivastava et al., 2014)\n",
        "  - Batch Normalization: Stabilizes training and allows higher learning rates (Ioffe & Szegedy, 2015)\n",
        "- **Optimizer Selection:**\n",
        "  - Adam: Adaptive learning rate, combines advantages of RMSprop and AdaGrad\n",
        "  - RMSprop: Good for non-stationary objectives\n",
        "  - SGD: Vanilla gradient descent with momentum potential\n",
        "- **Loss Function:** Binary cross-entropy for classification\n",
        "\n",
        "**Configuration Choices:**\n",
        "- Config 1: Simple architecture (64-32) with Adam for stable convergence\n",
        "- Config 2: Deeper network (128-64-32) with RMSprop for non-stationary financial patterns\n",
        "- Config 3: Wide shallow network (256-128) with tanh and BatchNorm for different representational capacity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing Justification\n",
        "\n",
        "### 1. Stratified Train-Test Split (80-20)\n",
        "**Reasoning:** \n",
        "- Maintains class distribution in both training and test sets\n",
        "- Prevents bias towards majority class (non-bankrupt companies)\n",
        "- Standard practice for imbalanced datasets\n",
        "\n",
        "### 2. Feature Scaling (StandardScaler)\n",
        "**Reasoning:**\n",
        "- Financial features have different scales and units (ratios, percentages, absolute values)\n",
        "- Required for logistic regression (coefficient interpretation and convergence)\n",
        "- Essential for neural networks (prevents features with larger scales from dominating)\n",
        "- StandardScaler: Z-score normalization → mean=0, std=1\n",
        "- Random Forest doesn't require scaling (tree-based, scale-invariant)\n",
        "\n",
        "### 3. Handling Class Imbalance\n",
        "**Strategies Applied:**\n",
        "- Stratified splitting preserves minority class in all folds\n",
        "- Balanced class weights in Random Forest Config 3\n",
        "- Early stopping in Neural Networks prevents overfitting to majority class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Improvement Suggestions\n",
        "\n",
        "### 1. **Feature Engineering & Selection**\n",
        "**Current Gap:** Using all 95 features without dimensionality reduction\n",
        "**Improvement:** \n",
        "- Apply PCA or Factor Analysis to reduce multicollinearity among financial ratios\n",
        "- Use feature importance scores to select top 20-30 most predictive features\n",
        "- Create interaction features (e.g., ROA × Debt Ratio)\n",
        "- Literature: Guyon & Elisseeff (2003) - Feature Selection for Machine Learning\n",
        "\n",
        "### 2. **Advanced Handling of Class Imbalance**\n",
        "**Current Gap:** Limited imbalance strategies\n",
        "**Improvements:**\n",
        "- Apply SMOTE (Synthetic Minority Oversampling Technique) to create synthetic bankrupt examples\n",
        "- Use weighted loss function in neural networks\n",
        "- Implement focal loss (Lin et al., 2017) to focus on hard examples\n",
        "- Try ADASYN (Adaptive Synthetic Sampling) for adaptive oversampling\n",
        "- Literature: Chawla et al. (2002) - SMOTE\n",
        "\n",
        "### 3. **Hyperparameter Optimization**\n",
        "**Current Gap:** Manual hyperparameter selection\n",
        "**Improvements:**\n",
        "- Implement Grid Search or Random Search with cross-validation\n",
        "- Use Bayesian Optimization (e.g., Optuna) for efficient hyperparameter tuning\n",
        "- Apply Early Stopping with learning rate scheduling\n",
        "- Use automated ML frameworks (AutoML)\n",
        "- Literature: Bergstra & Bengio (2012) - Random Search for Hyperparameter Optimization\n",
        "\n",
        "### 4. **Ensemble Methods**\n",
        "**Current Gap:** Models evaluated separately\n",
        "**Improvements:**\n",
        "- Stack multiple models (meta-learner approach)\n",
        "- Implement voting classifier (hard/soft voting)\n",
        "- Use gradient boosting (XGBoost, LightGBM) as additional model\n",
        "- Bagging with different algorithms\n",
        "- Literature: Wolpert (1992) - Stacked Generalization\n",
        "\n",
        "### 5. **Interpretability & Explainability**\n",
        "**Current Gap:** Limited model interpretability\n",
        "**Improvements:**\n",
        "- Apply SHAP (SHapley Additive exPlanations) values for feature importance\n",
        "- Use LIME (Local Interpretable Model-agnostic Explanations) for local explanations\n",
        "- Generate partial dependence plots for feature effects\n",
        "- Implement permutation importance\n",
        "- Literature: Lundberg & Lee (2017) - SHAP\n",
        "\n",
        "### 6. **Domain-Specific Feature Engineering**\n",
        "**Current Gap:** Using raw financial ratios only\n",
        "**Improvements:**\n",
        "- Engineer bankruptcy-specific features (Altman Z-score, Ohlson O-score)\n",
        "- Create temporal features if time-series data available\n",
        "- Industry-specific ratios and benchmarks\n",
        "- Macroeconomics indicators (market conditions, economic cycles)\n",
        "- Literature: Altman (1968) - Financial Ratios\n",
        "\n",
        "### References:\n",
        "1. Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*\n",
        "2. Breiman, L. (2001). \"Random Forests\". *Machine Learning*, 45(1)\n",
        "3. Glorot, X., et al. (2011). \"Deep sparse rectifier neural networks\"\n",
        "4. Lin, T. Y., et al. (2017). \"Focal Loss for Dense Object Detection\"\n",
        "5. Chawla, N. V., et al. (2002). \"SMOTE: Synthetic Minority Over-sampling Technique\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model performance comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "# Accuracy comparison\n",
        "axes[0, 0].barh(results_df['Model'], results_df['Accuracy'], color='steelblue', alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_xlabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# F1-Score comparison\n",
        "axes[0, 1].barh(results_df['Model'], results_df['F1-Score'], color='orange', alpha=0.7, edgecolor='black')\n",
        "axes[0, 1].set_xlabel('F1-Score', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_title('Model F1-Score Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# ROC-AUC comparison\n",
        "axes[1, 0].barh(results_df['Model'], results_df['ROC-AUC'], color='green', alpha=0.7, edgecolor='black')\n",
        "axes[1, 0].set_xlabel('ROC-AUC', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_title('Model ROC-AUC Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Precision comparison\n",
        "axes[1, 1].barh(results_df['Model'], results_df['Precision'], color='red', alpha=0.7, edgecolor='black')\n",
        "axes[1, 1].set_xlabel('Precision', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_title('Model Precision Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ROC Curves for all models\n",
        "fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
        "axes = axes.ravel()\n",
        "\n",
        "models_and_predictions = [\n",
        "    (results_lr1, y_pred_proba_lr1, \"LR Config 1\"),\n",
        "    (results_lr2, y_pred_proba_lr2, \"LR Config 2\"),\n",
        "    (results_lr3, y_pred_proba_lr3, \"LR Config 3\"),\n",
        "    (results_rf1, y_pred_proba_rf1, \"RF Config 1\"),\n",
        "    (results_rf2, y_pred_proba_rf2, \"RF Config 2\"),\n",
        "    (results_rf3, y_pred_proba_rf3, \"RF Config 3\"),\n",
        "    (results_nn1, y_pred_proba_nn1_formatted, \"NN Config 1\"),\n",
        "    (results_nn2, y_pred_proba_nn2_formatted, \"NN Config 2\"),\n",
        "    (results_nn3, y_pred_proba_nn3_formatted, \"NN Config 3\")\n",
        "]\n",
        "\n",
        "for i, (result, y_pred_proba, name) in enumerate(models_and_predictions):\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
        "    auc_score = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "    \n",
        "    axes[i].plot(fpr, tpr, linewidth=2, label=f\"AUC = {auc_score:.3f}\")\n",
        "    axes[i].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "    axes[i].set_xlabel('False Positive Rate', fontsize=10)\n",
        "    axes[i].set_ylabel('True Positive Rate', fontsize=10)\n",
        "    axes[i].set_title(f\"ROC Curve - {name}\", fontsize=11, fontweight='bold')\n",
        "    axes[i].legend(loc='lower right')\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Importance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance from best Random Forest model\n",
        "if hasattr(rf_model2, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': rf_model2.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    # Plot top 20 most important features\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    top_features = feature_importance.head(20)\n",
        "    plt.barh(range(len(top_features)), top_features['Importance'], color='crimson', alpha=0.7, edgecolor='black')\n",
        "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "    plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
        "    plt.title('Top 20 Most Important Features (Random Forest)', fontsize=14, fontweight='bold')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY AND CONCLUSIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nDataset: Company Bankruptcy Prediction\")\n",
        "print(f\"Problem Type: Binary Classification\")\n",
        "print(f\"Total Samples: {len(df)}\")\n",
        "print(f\"Features: {df.shape[1] - 1}\")\n",
        "print(f\"Target Variable: Bankrupt? (0 = Not Bankrupt, 1 = Bankrupt)\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"BEST PERFORMING MODELS\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nBest Overall Model (By ROC-AUC): {results_df.iloc[0]['Model']}\")\n",
        "print(f\"  - ROC-AUC: {results_df.iloc[0]['ROC-AUC']:.4f}\")\n",
        "print(f\"  - Accuracy: {results_df.iloc[0]['Accuracy']:.4f}\")\n",
        "print(f\"  - F1-Score: {results_df.iloc[0]['F1-Score']:.4f}\")\n",
        "\n",
        "print(f\"\\nSecond Best Model: {results_df.iloc[1]['Model']}\")\n",
        "print(f\"  - ROC-AUC: {results_df.iloc[1]['ROC-AUC']:.4f}\")\n",
        "print(f\"  - Accuracy: {results_df.iloc[1]['Accuracy']:.4f}\")\n",
        "print(f\"  - F1-Score: {results_df.iloc[1]['F1-Score']:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"KEY FINDINGS\")\n",
        "print(f\"{'='*80}\")\n",
        "print(\"\\n1. All models were tested with multiple configurations:\")\n",
        "print(\"   - Logistic Regression: 3 configurations (different regularization and C values)\")\n",
        "print(\"   - Random Forest: 3 configurations (different tree depths, estimators, and class weights)\")\n",
        "print(\"   - Neural Network: 3 configurations (different architectures, optimizers, and activations)\")\n",
        "print(\"\\n2. The dataset shows class imbalance which was addressed through:\")\n",
        "print(\"   - Stratified train/test splitting\")\n",
        "print(\"   - Class weight balancing in some Random Forest configurations\")\n",
        "print(\"\\n3. Feature scaling was applied to ensure optimal performance\")\n",
        "print(\"   for Logistic Regression and Neural Network models.\")\n",
        "print(\"\\n4. Performance metrics show that:\")\n",
        "print(f\"   - Highest ROC-AUC achieved: {results_df.iloc[0]['ROC-AUC']:.4f}\")\n",
        "print(f\"   - The models are effective in predicting company bankruptcy risk.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
